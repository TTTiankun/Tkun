
#如何让训练更加的稳定

#目标：让梯度在合理=范围内，不要太大，也不要太小
#手段：将乘法变为加法 
# 归一化 
# 梯度剪裁：将梯度限制在一个合理的范围内 
# 使用合理的激活函数和权重初始化方法

#思想
#将每一层的方差是一个常数 将每层的输出和梯度都看做随机变量 让它们的均值和方差都保持一致

#权重初始化
#在合理值区间里随机初始参数
#缺点：训练开始的时候容易出现数值不稳定
#   远离最优解的地方损失函数表面可能很复杂
#   最优解附近的损失函数表面可能很平滑
#   初始小网络没有什么问题，但是随着网络的加深，问题就会变得越来越严重

#正向方差 记得高中的方差公式吗？就是那个东西！
#反向方差 也就是梯度的方差
#Xavier初始化方法
#正向方差和反向方差相等
#正向方差和反向方差都是1/n
#n是输入的维度 也就是输入的个数

#使用泰勒展开可以检查激活函数
#在零点附近进行泰勒展开 发现是恒等函数 那么就满足条件

#RMSE 误差均方根
#这种参数用来评估回归模型预测效果的好坏 
#公式：sqrt(sum((y-y_hat)^2)/n) 即 y和y_hat的差的平方和的平均值的开方
#y是真实值 y_hat是预测值 n是样本个数
#RMSE越小，说明预测效果越好 缺点：容易受到异常值的影响
