#感知机

#给输入x,权重w,偏置b，输出-1或1

#超平面：
# 在数学和几何学中，超平面是一个维度比它所嵌入的空间低一维的线性子空间。在二维空间中，超平面是一条直线；在三维空间中，超平面是一个平面。更一般地，对于 n 维空间，超平面是一个 n-1 维的线性子空间。

# 数学上，一个超平面可以通过一个法向量（垂直于超平面的向量）和一个点（超平面上的一个点）来定义。超平面上的点 x 满足以下线性方程：

# w⋅x+b=0

# 其中，w 是法向量，⋅⋅ 表示点积，bb 是一个偏移量。这个方程表示超平面上的点满足法向量和点的线性组合等于常数 b。法向量确定了超平面的方向，而 b 决定了超平面的位置。

#感知机的输入输出关系是人为指定的，即人为指定感知机的模型
#感知机的学习目的是求出合适的参数w和b，使得感知机的输出值尽可能接近真实值
#感知机的学习规则是误分类点的梯度下降法，即误分类点沿着梯度方向移动，直到被正确分类为止
#感知机的学习策略是极小化损失函数，即误分类点到超平面的总距离

#收敛定理：如果训练数据集是线性可分的，那么感知机学习算法是收敛的，即经过有限次迭代可以得到一个将训练数据集完全正确分开的分离超平面w和b

#感知机的局限性：感知机只能解决线性可分的问题，不能解决线性不可分的问题 例如：XOR函数无法拟合

#多层感知机
#多层感知机是由输入层、输出层和若干个隐藏层组成，隐藏层和输出层都是全连接层

#XOR问题
#XOR函数是异或函数，当两个输入相同时，输出为0，否则输出为1
#意思就是先分一次再分一次，就可以把XOR函数拟合出来，不行就再分一次，直到拟合出来为止 每分一次就是一个隐藏层

#单层隐藏 分类层 输出之后还是线性可分的

#激活函数
#激活函数的作用是引入非线性因素，使得神经网络可以拟合非线性函数

#sigmoid函数
#sigmoid函数是一个S型的函数，其函数表达式为：f(x)=1/(1+e^(-x))

#tanh函数
#tanh函数是一个S型的函数，其函数表达式为：f(x)=tanh(x)=1-e^(-2x)/(1+e^(-2x))

#ReLU函数
#ReLU函数是一个分段函数，其函数表达式为：f(x)=max(x,0)

#多类分类问题
#重要超参数：影藏层数 每层隐藏层的大小