#模型优化

#模型剪枝
#意义：减少参数值小于一定阈值的参数，减少模型大小，提高模型运行速度

#剪枝的不同粒度
#1.权重级别：对权重进行剪枝
#2.向量级别：对权重向量进行剪枝
#这两种叫非结构化剪枝

#3.通道级别：对卷积核进行剪枝
#4.卷积核级别：对卷积核进行剪枝
#这两种叫结构化剪枝

#例子：
#Dropout/Dropconnect 结构化剪枝
#Dropout是一种正则化方法，通过随机丢弃一部分神经元的输出特征，来减少过拟合
#Dropconnect是Dropout的一种扩展，不是丢弃神经元的输出特征，而是丢弃神经元之间的连接

#权重的冗余度
#1.滤波器的冗余性 卷积核存在相位互补性 越是网络浅的层，统计上越容易出现相位互补性

#非结构化剪枝
#剪枝的流程：1.判断神经元的重要性 2.剪枝 3.微调 4.重复1-3

#恢复权重法：有些权重被剪枝后，可能会对模型的性能产生影响，可以通过恢复权重法来恢复模型的性能
#实现方法：掩膜矩阵：通过掩膜矩阵来恢复权重

#结构化剪枝
#权重法：通过判断权重的范数来判断权重的重要性 从而对滤波器进行剪枝
#裁剪方法：计算卷积核的绝对值的和，然后对卷积核进行排序，然后去掉一部分卷积核

#稀疏权重法：对权重进行稀疏化处理，然后对稀疏化后的权重进行剪枝
#实现方法：1.对权重进行稀疏化处理 2.对稀疏化后的权重进行剪枝
#稀疏化处理方法：1.对权重进行L1正则化 2.对权重进行L0正则化 3.对权重进行L2正则化

#因子法：基于BN缩放因子对模型的容量进行剪枝
#实现方法：1.对BN缩放因子进行排序 2.对缩放因子进行剪枝

#重建法：通过重建法来恢复模型的性能
#实现方法：裁掉一部分卷积核后，然后对模型进行重建



